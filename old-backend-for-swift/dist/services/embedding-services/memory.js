/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * ðŸ’¾ MEMORY EMBEDDING OPERATIONS
 *
 * Core memory embedding CRUD operations for psychological content storage and retrieval.
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
import { createSupabaseClient } from "@/utils/database";
import { generateEmbedding } from "./core";
// Simple env flag reader
function isEnabled(env, key, defaultValue = true) {
    const raw = env?.[key];
    if (raw === undefined || raw === null)
        return defaultValue;
    const val = String(raw).toLowerCase();
    return val === "true" || val === "1" || val === "yes";
}
function normalizeText(text) {
    return text.trim().replace(/\s+/g, " ").toLowerCase();
}
async function computeSha256Hex(input) {
    // Prefer Web Crypto (Workers), fallback to Node crypto
    try {
        // @ts-ignore
        const subtle = crypto?.subtle;
        if (subtle) {
            const enc = new TextEncoder().encode(input);
            const hashBuffer = await subtle.digest("SHA-256", enc);
            const bytes = Array.from(new Uint8Array(hashBuffer));
            return bytes.map((b) => b.toString(16).padStart(2, "0")).join("");
        }
    }
    catch (_) {
        // ignore and fallback
    }
    const { createHash } = await import("crypto");
    return createHash("sha256").update(input).digest("hex");
}
/**
 * ðŸ“š Retrieve All Psychological Memory Embeddings for User
 *
 * Fetches the complete psychological memory bank for a user, including all
 * embedded patterns, excuses, breakthroughs, and behavioral data. Used for
 * comprehensive pattern analysis and personalized accountability responses.
 *
 * @param userId - Target user's psychological memory bank
 * @param env - Database environment configuration
 * @returns Complete memory embedding records with vectors and metadata
 *
 * ðŸ§  Returned Data Structure:
 * â€¢ id, user_id, source_id - Record identifiers
 * â€¢ content_type - Pattern category (excuse, breakthrough, etc.)
 * â€¢ text_content - Original psychological text
 * â€¢ embedding - 1536-dimensional vector
 * â€¢ metadata - Additional context and timestamps
 */
export async function getMemoryEmbeddings(userId, env) {
    const supabase = createSupabaseClient(env);
    console.log(`ðŸ“š Retrieving memory embeddings for user ${userId}`);
    const { data, error } = await supabase
        .from("memory_embeddings")
        .select("*")
        .eq("user_id", userId);
    if (error) {
        console.error("ðŸ’¥ Failed to retrieve memory embeddings:", error);
        throw error;
    }
    console.log(`âœ… Retrieved ${data?.length || 0} memory embeddings`);
    return data;
}
/**
 * ðŸ’¾ Create New Psychological Memory Embedding
 *
 * Generates and stores a new memory embedding for psychological content. Each
 * memory becomes searchable via semantic similarity, enabling the AI to reference
 * past patterns, excuses, breakthroughs for personalized accountability.
 *
 * @param userId - User who owns this psychological memory
 * @param sourceId - Source identifier (call_id, identity_record_id, etc.)
 * @param contentType - Memory category (excuse, breakthrough, trigger_moment, etc.)
 * @param textContent - Actual psychological text to embed and remember
 * @param env - Environment with database and OpenAI access
 * @returns Created memory embedding record with generated vector
 *
 * ðŸ”® Memory Creation Process:
 * 1. Generate 1536-dimensional embedding vector via OpenAI
 * 2. Store in memory_embeddings table with metadata
 * 3. Enable future semantic search and pattern recognition
 * 4. Return complete record for immediate use
 */
export async function createMemoryEmbedding(userId, sourceId, contentType, textContent, env, extraMetadata) {
    const supabase = createSupabaseClient(env);
    console.log(`ðŸ’¾ Creating ${contentType} memory for user ${userId}: "${textContent.substring(0, 50)}..."`);
    // Normalize only for hashing (do not alter stored text)
    const normalized = normalizeText(textContent);
    const textHash = await computeSha256Hex(normalized);
    // Idempotency: skip if same user+source+text_hash already stored
    try {
        const { data: existing, error: existingErr } = await supabase
            .from("memory_embeddings")
            .select("id")
            .eq("user_id", userId)
            .eq("source_id", sourceId)
            .contains("metadata", { text_hash: textHash });
        if (!existingErr && Array.isArray(existing) && existing.length > 0) {
            console.log("â™»ï¸ Skipping duplicate memory (hash match)");
            return { id: existing[0].id };
        }
    }
    catch (e) {
        console.warn("Duplicate check failed (continuing)", e);
    }
    // ðŸ”® Generate embedding vector for psychological content
    const embedding = await generateEmbedding(textContent, env);
    const { data, error } = await supabase
        .from("memory_embeddings")
        .insert({
        user_id: userId,
        source_id: sourceId,
        content_type: contentType,
        text_content: textContent,
        embedding,
        metadata: {
            created_at: new Date().toISOString(),
            text_length: textContent.length,
            text_hash: textHash,
            ...(extraMetadata || {}),
        },
    })
        .select()
        .single();
    if (error) {
        console.error("ðŸ’¥ Failed to create memory embedding:", error);
        throw error;
    }
    console.log(`âœ… Created ${contentType} memory embedding with ID: ${data.id}`);
    return data;
}
/**
 * ðŸ” Search Psychological Memory Bank via Semantic Similarity
 *
 * Finds similar psychological patterns from user's memory bank using vector
 * similarity search. Powers accountability calls with personalized references
 * to past behaviors, excuses, breakthroughs, and commitments.
 *
 * @param userId - User's psychological memory bank to search
 * @param query - Current psychological content to match against memories
 * @param matchThreshold - Similarity threshold (0.7 = 70% similar, 0.8 = stricter)
 * @param matchCount - Maximum similar memories to return (default: 5)
 * @param env - Environment with database and OpenAI access
 * @returns Ranked array of similar memories with similarity scores
 *
 * ðŸŽ¯ Accountability Use Cases:
 * â€¢ Query: "I'm too busy today" â†’ Find: Similar excuse patterns
 * â€¢ Query: "I want to give up" â†’ Find: Past breakthrough moments
 * â€¢ Query: Current behavior â†’ Find: Previous commitment violations
 *
 * ðŸ“Š Similarity Thresholds:
 * â€¢ 0.9+ = Nearly identical (exact pattern match)
 * â€¢ 0.8+ = Very similar (strong pattern recognition)
 * â€¢ 0.7+ = Similar theme (useful for accountability)
 * â€¢ 0.6+ = Loosely related (broader pattern detection)
 */
export async function searchMemoryEmbeddings(userId, query, matchThreshold = 0.7, matchCount = 5, env) {
    const supabase = createSupabaseClient(env);
    console.log(`ðŸ” Searching memories for user ${userId}: "${query.substring(0, 50)}..." (threshold: ${matchThreshold})`);
    // ðŸ”® Generate query embedding for semantic comparison
    const queryEmbedding = await generateEmbedding(query, env);
    // ðŸŽ¯ Call PostgreSQL RPC function for optimized vector similarity search
    const { data, error } = await supabase.rpc("match_memory_embeddings", {
        query_embedding: queryEmbedding,
        match_threshold: matchThreshold,
        match_count: matchCount,
        target_user_id: userId,
    });
    if (error) {
        console.error("ðŸ’¥ Memory search failed:", error);
        throw error;
    }
    console.log(`âœ… Found ${data?.length || 0} similar memories above ${matchThreshold} threshold`);
    return data;
}
/**
 * ðŸŽ¯ Search Memories by Specific Content Types
 *
 * Specialized search that filters by psychological content types for targeted
 * accountability responses. Perfect for finding specific patterns like excuses,
 * breakthroughs, or trigger moments.
 *
 * @param userId - User's memory bank to search
 * @param query - Current psychological content to match
 * @param contentTypes - Array of content types to search within
 * @param matchThreshold - Similarity threshold (default: 0.7)
 * @param matchCount - Maximum results to return (default: 5)
 * @param env - Environment configuration
 * @returns Filtered and ranked similar memories by type
 *
 * ðŸ’¡ Example Usage:
 * â€¢ searchPsychologicalPatterns(userId, "I'm too tired", ["excuse", "excuse_pattern"])
 * â€¢ searchPsychologicalPatterns(userId, "giving up", ["breakthrough", "vision"])
 * â€¢ searchPsychologicalPatterns(userId, "morning routine", ["trigger_moment", "commitment"])
 */
export async function searchPsychologicalPatterns(userId, query, contentTypes, matchThreshold = 0.7, matchCount = 5, env) {
    const supabase = createSupabaseClient(env);
    console.log(`ðŸŽ¯ Searching ${contentTypes.join(", ")} patterns for: "${query.substring(0, 50)}..."`);
    // ðŸ”® Generate query embedding
    const queryEmbedding = await generateEmbedding(query, env);
    // ðŸŽ¯ Search with content type filtering
    const { data, error } = await supabase.rpc("match_memory_embeddings", {
        query_embedding: queryEmbedding,
        match_threshold: matchThreshold,
        match_count: matchCount * 2, // Get more results for filtering
        target_user_id: userId,
    });
    if (error) {
        console.error("ðŸ’¥ Pattern search failed:", error);
        throw error;
    }
    // ðŸ” Filter by requested content types and limit results
    const filteredResults = data
        .filter((result) => contentTypes.includes(result.content_type))
        .slice(0, matchCount);
    console.log(`âœ… Found ${filteredResults.length} matching ${contentTypes.join("/")} patterns`);
    return filteredResults;
}
/**
 * ðŸ§© Build a compact payload for prompt enrichment from Top-K related memories
 * Returns a small object with related_memories and a one-line pattern_summary
 */
export async function buildRelatedMemoriesPayload(userId, query, env, matchThreshold = 0.7, matchCount = 5) {
    const results = await searchMemoryEmbeddings(userId, query, matchThreshold, matchCount, env);
    const related_memories = (results || [])
        .slice(0, 3)
        .map((r) => {
        const meta = r.metadata || {};
        const date = (meta.call_date || r.created_at || new Date().toISOString()).slice(0, 10);
        const emotion = meta.emotion || meta.tone_used ||
            undefined;
        return { text: r.text_content, date, emotion };
    });
    // Simple summary: dominant type + brief phrasing
    const typeCounts = {};
    (results || []).forEach((r) => {
        const t = String(r.content_type || "pattern");
        typeCounts[t] = (typeCounts[t] || 0) + 1;
    });
    const topType = Object.entries(typeCounts).sort((a, b) => b[1] - a[1])[0]?.[0] || "pattern";
    let pattern_summary = "Relevant past situations detected.";
    if (topType === "excuse") {
        pattern_summary =
            "User repeats similar excuse patterns in comparable contexts.";
    }
    else if (topType === "breakthrough") {
        pattern_summary =
            "Past breakthroughs in similar contexts can be leveraged now.";
    }
    else {
        pattern_summary =
            "Recurring behavioral patterns align with today's context.";
    }
    return { related_memories, pattern_summary };
}
/**
 * ðŸ“Š Get Memory Insights (Processed Data Instead of Raw Embeddings)
 *
 * Instead of exposing raw memory embeddings to UserContext, this function returns
 * processed insights, statistics, and behavioral indicators while protecting
 * sensitive psychological content.
 *
 * @param userId - User to analyze memory patterns for
 * @param env - Environment configuration
 * @returns Processed insights without raw memory content
 *
 * ðŸ›¡ï¸ Privacy Protection:
 * â€¢ No raw psychological text content exposed
 * â€¢ Statistical summaries instead of specific memories
 * â€¢ Behavioral trend indicators without specific examples
 * â€¢ Count-based metrics for accountability patterns
 */
export async function getMemoryInsights(userId, env) {
    const supabase = createSupabaseClient(env);
    console.log(`ðŸ“Š Generating memory insights for user ${userId}`);
    // Fetch all memory embeddings for analysis
    const { data: memories, error } = await supabase
        .from("memory_embeddings")
        .select("id, content_type, created_at, metadata")
        .eq("user_id", userId)
        .order("created_at", { ascending: false });
    if (error) {
        console.error("Failed to fetch memories for insights:", error);
        throw error;
    }
    const now = new Date();
    const sevenDaysAgo = new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000);
    const fourteenDaysAgo = new Date(now.getTime() - 14 * 24 * 60 * 60 * 1000);
    // ðŸ“ˆ Calculate memory statistics
    const totalMemories = memories?.length || 0;
    const recentMemories = memories?.filter(m => new Date(m.created_at) > sevenDaysAgo).length || 0;
    const previousWeekMemories = memories?.filter(m => {
        const date = new Date(m.created_at);
        return date > fourteenDaysAgo && date <= sevenDaysAgo;
    }).length || 0;
    // Content type breakdown
    const contentTypeBreakdown = {};
    memories?.forEach(memory => {
        const type = memory.content_type || "unknown";
        contentTypeBreakdown[type] = (contentTypeBreakdown[type] || 0) + 1;
    });
    // Weekly trend analysis
    let weeklyTrend = "stable";
    if (recentMemories > previousWeekMemories * 1.2) {
        weeklyTrend = "increasing";
    }
    else if (recentMemories < previousWeekMemories * 0.8) {
        weeklyTrend = "decreasing";
    }
    // ðŸ§  Behavioral indicators
    const excuseCount = contentTypeBreakdown["excuse"] || 0;
    const breakthroughCount = contentTypeBreakdown["breakthrough"] || 0;
    const patternCount = contentTypeBreakdown["pattern"] || 0;
    const excuseFrequency = excuseCount > 10 ? "high" : excuseCount > 3 ? "moderate" : "low";
    const patternStrength = patternCount > 15 ? "strong" : patternCount > 5 ? "moderate" : "weak";
    // Emotional trend analysis (simplified - would use sentiment analysis in production)
    const positiveTypes = ["breakthrough", "vision", "commitment", "sacred_oath"];
    const negativeTypes = ["excuse", "excuse_pattern", "self_deception"];
    const positiveCount = positiveTypes.reduce((sum, type) => sum + (contentTypeBreakdown[type] || 0), 0);
    const negativeCount = negativeTypes.reduce((sum, type) => sum + (contentTypeBreakdown[type] || 0), 0);
    const emotionalTrend = positiveCount > negativeCount * 1.5 ? "positive" :
        negativeCount > positiveCount * 1.5 ? "negative" : "neutral";
    // ðŸŽ¯ Accountability signals
    const recurringPatternCount = Math.max(excuseCount, patternCount);
    const lastMemoryDate = memories?.[0]?.created_at || null;
    const criticalThemesCount = Object.keys(contentTypeBreakdown).length;
    const growthIndicators = breakthroughCount + (contentTypeBreakdown["vision"] || 0);
    // ðŸ› ï¸ System health
    const dataQualityScore = Math.min(100, Math.max(0, (totalMemories * 10) + (criticalThemesCount * 15) - (excuseCount * 2)));
    const insights = {
        memoryStats: {
            totalMemories,
            recentMemories,
            contentTypeBreakdown,
            weeklyTrend,
        },
        behavioralIndicators: {
            excuseFrequency,
            breakthroughMoments: breakthroughCount,
            patternStrength,
            emotionalTrend,
        },
        accountabilitySignals: {
            recurringPatternCount,
            lastMemoryDate,
            criticalThemesCount,
            growthIndicators,
        },
        systemHealth: {
            memorySystemActive: totalMemories > 0,
            lastProcessedAt: new Date().toISOString(),
            dataQualityScore,
        },
    };
    console.log(`âœ… Generated memory insights: ${totalMemories} memories, ${recentMemories} recent, ${criticalThemesCount} themes`);
    return insights;
}
